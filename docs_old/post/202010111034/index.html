<!DOCTYPE html><head><title>RidgeClassifier 中的 SAG - 兴趣使然的无名小站</title><meta name="description" content=""><script src="/bundle.js" onload="[].flat||(location='/update.html')"></script></head><main><article><h1>RidgeClassifier 中的 SAG</h1><pre><code class="language-python">
class _BaseRidge(LinearModel, metaclass=ABCMeta):
    @abstractmethod
    @_deprecate_positional_args
    def __init__(self, alpha=1.0, *, fit_intercept=True, normalize=False,
                 copy_X=True, max_iter=None, tol=1e-3, solver=&quot;auto&quot;,
                 random_state=None):
        self.alpha = alpha
        self.fit_intercept = fit_intercept
        self.normalize = normalize
        self.copy_X = copy_X
        self.max_iter = max_iter
        self.tol = tol
        self.solver = solver
        self.random_state = random_state

    def fit(self, X, y, sample_weight=None):

        # all other solvers work at both float precision levels
        _dtype = [np.float64, np.float32]
        _accept_sparse = _get_valid_accept_sparse(sparse.issparse(X),
                                                  self.solver)
        X, y = self._validate_data(X, y,
                                   accept_sparse=_accept_sparse,
                                   dtype=_dtype,
                                   multi_output=True, y_numeric=True)
        if sparse.issparse(X) and self.fit_intercept:
            if self.solver not in [&#39;auto&#39;, &#39;sparse_cg&#39;, &#39;sag&#39;]:
                raise ValueError(
                    &quot;solver=&#39;{}&#39; does not support fitting the intercept &quot;
                    &quot;on sparse data. Please set the solver to &#39;auto&#39; or &quot;
                    &quot;&#39;sparse_cg&#39;, &#39;sag&#39;, or set `fit_intercept=False`&quot;
                    .format(self.solver))
            if (self.solver == &#39;sag&#39; and self.max_iter is None and
                    self.tol &gt; 1e-4):
                warnings.warn(
                    &#39;&quot;sag&quot; solver requires many iterations to fit &#39;
                    &#39;an intercept with sparse inputs. Either set the &#39;
                    &#39;solver to &quot;auto&quot; or &quot;sparse_cg&quot;, or set a low &#39;
                    &#39;&quot;tol&quot; and a high &quot;max_iter&quot; (especially if inputs are &#39;
                    &#39;not standardized).&#39;)
                solver = &#39;sag&#39;
            else:
                solver = &#39;sparse_cg&#39;
        else:
            solver = self.solver

        if sample_weight is not None:
            sample_weight = _check_sample_weight(sample_weight, X,
                                                 dtype=X.dtype)

        # when X is sparse we only remove offset from y
        X, y, X_offset, y_offset, X_scale = self._preprocess_data(
            X, y, self.fit_intercept, self.normalize, self.copy_X,
            sample_weight=sample_weight, return_mean=True)

        if solver == &#39;sag&#39; and sparse.issparse(X) and self.fit_intercept:
            self.coef_, self.n_iter_, self.intercept_ = _ridge_regression(
                X, y, alpha=self.alpha, sample_weight=sample_weight,
                max_iter=self.max_iter, tol=self.tol, solver=&#39;sag&#39;,
                random_state=self.random_state, return_n_iter=True,
                return_intercept=True, check_input=False)
            # add the offset which was subtracted by _preprocess_data
            self.intercept_ += y_offset

        else:
            if sparse.issparse(X) and self.fit_intercept:
                # required to fit intercept with sparse_cg solver
                params = {&#39;X_offset&#39;: X_offset, &#39;X_scale&#39;: X_scale}
            else:
                # for dense matrices or when intercept is set to 0
                params = {}

            self.coef_, self.n_iter_ = _ridge_regression(
                X, y, alpha=self.alpha, sample_weight=sample_weight,
                max_iter=self.max_iter, tol=self.tol, solver=solver,
                random_state=self.random_state, return_n_iter=True,
                return_intercept=False, check_input=False, **params)
            self._set_intercept(X_offset, y_offset, X_scale)

        return self
</code></pre><p>RidgeClassifier机器学习模型(和logistic(sigmoid)激励函数不同，非logistic类模型)继承于此类 _BaseRidge，在其中fix中使用的solver(即我们常说的优化器算法)为sag，即</p><pre><code class="language-bash">    SAG stands for Stochastic Average Gradient: the gradient of the loss is
    estimated each sample at a time and the model is updated along the way with
    a constant learning rate.</code></pre><p>后续会更新R语言实现的数学表示。</p></article></main>